---
title: "Remote storage solutions"
author: "Aaron Berdanier"
date: "May 8, 2017"
output:
  html_document:
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: false
---

# Overview

In the workshop I will show you how to deply apps through shinyapps.io. Shinyapps is great, but they don't yet let you modify data stored on the shinyapps server through the app (apparently it is coming soon) (**note** you can upload as much static content as you want as long as the whole app is less than 100MB -- but beware of memory usage in the app). 

Thus, to update and save your database, you need to use a remote storage solution. There are four great options for some free remote storage. In my mind there is a tradeoff between efficiency and ease of use:

```{r echo=FALSE}
solutions <- c("MongoDB","Amazon S3","Dropbox","Google Sheets")
ease <- c(1,2,3,2.8)
efficiency <- c(4,3.5,2,1)
plot(0,0,xlim=c(0,4),ylim=c(0,5),type="n",bty="l", 
     xlab="Ease of use →",ylab="Efficiency/speed →",xaxt="n",yaxt="n")
text(ease,efficiency,solutions)
```

I've ordered them here by what I think is the best for our application. You can use whatever you want. If you didn't do any of this before hand, you can still write to a local .csv file and it should work (but shinyapps.io won't store any of the data long-term).

## A note on git

If you use version control, you will want to add these file names to your `.gitignore` file because they contain private information that you don't want to leak:

```
.Rproj.user
.Rhistory
.RData
.Ruserdata
global.R
*.rds
.httr-oauth
```

# MongoDB

MongoDB is a NoSQL database system, which means that it can take structured or unstructured data. The storage is similar to JSON and each row (what they call a "document") is stored as a separate item. *mLab* lets you set up a free cloud-hosted MongoDB that is smaller than 500MB.

## Setting up an account

1. Go to [mlab.com](www.mlab.com) and click "Get 500 MB Free!"
2. Create your account
3. Under MongoDB Deployments, go to "Create New > Single-node plan > Standard line/Sandbox/FREE"
4. Name the database (and write it down somewhere) and click "Create new MongoDB deployment"
5. Click "Users > Add database user", remember <dbuser> and <dbpassword>
6. Copy the weird url on your dashboard (something like `mongodb://<dbuser>:<dbpassword>@ds123456.mlab.com:33333/shinyshop`)
7. Install [`mongolite`](https://github.com/jeroen/mongolite) in R: `install.packages('mongolite')`

## In a `global.R` file

This is where we're going to give Shiny acccess to your mLab account.

```
library(mongolite)
# Yo, don't share this stuff!
# Get this information from your mlab dashboard
dbuser <- "yourusername"
dbpassword <- "yourpassword"
dburl <- sprintf("mongodb://%s:%s@ds131041.mlab.com:31041/shinyshop", dbuser, dbpassword)
# Replace <dbuser> and <dbpassword> in the mlab url with %s
db <- mongo(collection = "data2", url = dburl)

save_db <- function(dat){
  db$insert(dat)
}
load_db <- function(){
  dd <- db$find()
  return(dd)
}
```


# Amazon S3

Amazon's Simple Storage Service lets you store objects in a cloud folder (they call them "buckets"). This API lets you store Rdata objects (which are compressed dramatically and easy to reload into R) directly. Plus, Amazon lets you store 5GB of data for free (see... Bezos isn't so bad)!

## Setting up an account

1. Go to [aws.amazon.com](aws.amazon.com) and create an AWS account
2. Then, go to the S3 console and "Create Bucket"
3. Name your bucket whatever you want (we need to remember it)
4. Go to "My Account > Security Credentials > Access Keys > Create New Access Key" and copy down your access key ID and secret access key *(note: this is not the best practice, but it is easier than setting up a new IAM access account)*
5. Install [`aws.S3`](https://github.com/cloudyr/aws.s3) in R: `install.packages('aws.s3')`

## In a `global.R` file

This is where we're going to give Shiny acccess to your AWS account.

```
library(aws.s3)
# Yo, don't share this stuff!
Sys.setenv("AWS_ACCESS_KEY_ID" = "yourawsaccesskeyid",
           "AWS_SECRET_ACCESS_KEY" = "yourawssecretaccesskey")
aws_bucket <- "shinyshop"

# These are functions that we'll use to access and edit the data
save_db <- function(dat, bucket=aws_bucket){
  dat <- rbind(mydata$x, dat)
    # note, this is sloppy coding, functions don't usually call outside variables
  s3save(dat, bucket=bucket, object="data.Rda")
}
load_db <- function(){
  s3load("data.Rda", aws_bucket)
  return(dat)
}
```


# Dropbox

Dropbox is a cloud-based folder system. With this API, you need to locally save a .csv file when you want to upload/download files. That makes it pretty inefficient for our purposes. The benefit is that you can then access the files from your dropbox connection.

## Setting up an account

1. Create a Dropbox account
2. Install [`rdrop2`](https://github.com/karthik/rdrop2) in R: `install.packages('rdrop2')`

## Initializing things in R

Before you can connect with rdrop2, we need to authorize R to access your Dropbox account. You'll do this in an R console that has your shiny folder as a working directory. You only do this once and *do not* copy the code into your shiny `app.R`.

```
library(rdrop2)
token <- drop_auth()
# Yo, don't share your token!
saveRDS(token, "droptoken.rds")
dbfolder <- "shinyshop"
drop_create(dbfolder)
```


## In a `global.R` file

This is where we're going to give Shiny acccess to your Dropbox account.

```
library(rdrop2)
token <- readRDS("droptoken.rds")
# Then pass the token to each drop_ function
drop_acc(dtoken = token)
db_folder <- "shinyshop"

save_db <- function(dat) {
  dat <- rbind(mydata$x, dat)
    # note, this is sloppy coding, functions don't usually call outside variables
  file_path <- file.path(tempdir(), "data.csv") # create temporary file
  write.csv(dat, file_path, row.names = FALSE)
  drop_upload(file_path, dest = db_folder)
}

load_db <- function() {
  dd <- drop_read_csv(file.path(db_folder,"data.csv"))
  return(dd)
}
```

# Google Sheets

Google Sheets is like Excel on the cloud. This API is pretty slow (think about your users!), but has the benefit of being accessible from your browser through Google Docs.

## Setting up an account

1. Create a Google account
2. Install [`googlesheets`](https://github.com/jennybc/googlesheets) in R: `install.packages('googlesheets')`

## Initializing things in R

Before you can connect with googlesheets, we need to authorize R to access your Google account. You'll do this in an R console that has your shiny folder as a working directory. You only do this once and *do not* copy the code into your shiny `app.R`.

```
library(googlesheets)
shiny_token <- gs_auth() # authenticate
# Yo, don't share your token!
saveRDS(shiny_token, "shiny_app_token.rds")
# need to initialize with our columns and a blank row (unfortunately)
initial_sheet <- data.frame(addtime=0, site=0, weather=0, nwidgets=0)
gdoc_name <- "shinyshop"
ss <- gs_new(gdoc_name, input=initial_sheet)
sheetkey <- ss$sheet_key
sheetkey # write this down or copy it, something like "10kYZGTfXquVUwvBXH-8M-p01csXN6MNuuTzxnDdy3Pk"
```


## In a `global.R` file

This is where we're going to give Shiny acccess to your Google Sheets account.

```
library(googlesheets)
# load the sheet
sheetkey <- "yoursheetkey" # from the previous step
ss <- gs_key(sheetkey)

save_db <- function(dat){
  # this loops over rows...
  apply(dat, 1, function(x) gs_add_row(ss, input=x, verbose=FALSE))
}
load_db <- function(){
  dd <- gs_read(ss)
  # this checks if all the entries are zero... to omit
  is_zero <- suppressWarnings(apply(dd, 1, function(x) all(as.numeric(x)==0)))
  return(dd[!is_zero, ])
}
```

# If you didn't set stuff up in advance

You get to save and access the data "locally" -- i.e., you write data to the server computer.

This is an easier way to store data if you are testing an app on your personal computer or if you are hosting an app on your own server. However, the code that I wrote below will automatically overwrite the csv file with each new user. If you want persistent storage, you can modify the code to not rewrite the file each time. 

*Note:* If you are using shinyapps.io, you are allowed to write data to the shinyapps.io server but it will get deleted everytime the remote computer reboots (which is pretty often).

## Saving data to a local .csv

You can append data to an existing csv file with the `append=TRUE` command in write.csv(). So easy.
```
write.csv(mydataframe, file="database.csv", 
  append=TRUE, row.names=FALSE, col.names=FALSE)
```

You can also just save and load .Rdata files -- compressed for fast data access!

## In a `global.R` file

Some functions to match the other options.
```
# This makes a new sheet with each user session
initial_sheet <- data.frame(addtime=character(), site=character(), 
  weather=numeric(), nwidgets=numeric())
write.csv(initial_sheet, file="data.csv", row.names=FALSE)
save_db <- function(dat){
  write.table(dat, file="data.csv", sep=",", 
    append=TRUE, row.names=FALSE, col.names=FALSE)
}
load_db <- function(){
  dat <- read.csv("data.csv")
  return(dat)
}

```


# More information

All of this stuff is modified from [an article by Dean Attali](https://shiny.rstudio.com/articles/persistent-data-storage.html). That page has info about other options, too.